{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-19T22:46:45.962293Z",
     "start_time": "2024-05-19T22:46:45.144183Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T22:53:37.970835Z",
     "start_time": "2024-05-19T22:53:37.574176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "names = ['crime', 'zone', 'industry', 'charles', 'no', 'rooms', 'age', 'distance', 'radial', 'tax', 'pupil', 'aam',\n",
    "         'lower', 'med_price']\n",
    "data = pd.read_csv('../data/housing.csv', names=names)\n",
    "X, y = data.iloc[:, :-1].values, data.iloc[:, -1].values\n",
    "rf_pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('rf', RandomForestRegressor())])\n",
    "scores = cross_val_score(rf_pipeline, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "final_avg_rmse = np.mean(np.sqrt(np.abs(scores)))\n",
    "print('Final  RMSE:', final_avg_rmse)"
   ],
   "id": "6d6a321765e6ff4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1279, in check_X_y\n    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1289, in _check_y\n    y = check_array(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1049, in check_array\n    _assert_all_finite(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 126, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 175, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input y contains NaN.\n\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 876, in fit\n    return self.partial_fit(X, y, sample_weight)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 912, in partial_fit\n    X = self._validate_data(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 997, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py\", line 521, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'RM'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m X, y \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39miloc[:, :\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues, data\u001B[38;5;241m.\u001B[39miloc[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m      5\u001B[0m rf_pipeline \u001B[38;5;241m=\u001B[39m Pipeline(steps\u001B[38;5;241m=\u001B[39m[(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscaler\u001B[39m\u001B[38;5;124m'\u001B[39m, StandardScaler()), (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrf\u001B[39m\u001B[38;5;124m'\u001B[39m, RandomForestRegressor())])\n\u001B[0;32m----> 6\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrf_pipeline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mneg_mean_squared_error\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m final_avg_rmse \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(np\u001B[38;5;241m.\u001B[39msqrt(np\u001B[38;5;241m.\u001B[39mabs(scores)))\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFinal  RMSE:\u001B[39m\u001B[38;5;124m'\u001B[39m, final_avg_rmse)\n",
      "File \u001B[0;32m~/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:719\u001B[0m, in \u001B[0;36mcross_val_score\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001B[0m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[1;32m    717\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[0;32m--> 719\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    720\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    721\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    722\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    723\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    724\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    725\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    726\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    727\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    728\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    729\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    730\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    731\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    732\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    733\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:450\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[0m\n\u001B[1;32m    429\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m    430\u001B[0m results \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[1;32m    431\u001B[0m     delayed(_fit_and_score)(\n\u001B[1;32m    432\u001B[0m         clone(estimator),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m indices\n\u001B[1;32m    448\u001B[0m )\n\u001B[0;32m--> 450\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(scoring):\n",
      "File \u001B[0;32m~/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:536\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[0;34m(results, error_score)\u001B[0m\n\u001B[1;32m    529\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[1;32m    530\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    531\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    532\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    533\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    534\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    535\u001B[0m     )\n\u001B[0;32m--> 536\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[1;32m    538\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    539\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    540\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    541\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    545\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    546\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1279, in check_X_y\n    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1289, in _check_y\n    y = check_array(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1049, in check_array\n    _assert_all_finite(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 126, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 175, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input y contains NaN.\n\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 876, in fit\n    return self.partial_fit(X, y, sample_weight)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\", line 912, in partial_fit\n    X = self._validate_data(\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 633, in _validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 997, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/home/sajjad/PycharmProjects/ml-xgboost/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py\", line 521, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'RM'\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
